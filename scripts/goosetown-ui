#!/usr/bin/env python3
"""goosetown-ui â€” Real-time dashboard server for goosetown orchestrator sessions."""

import argparse, asyncio, glob, json, os, re, sqlite3, sys, time
from collections import deque
from contextlib import contextmanager
from datetime import datetime
from pathlib import Path

import uvicorn
from starlette.applications import Starlette
from starlette.middleware import Middleware
from starlette.middleware.base import BaseHTTPMiddleware
from starlette.responses import JSONResponse, RedirectResponse, StreamingResponse
from starlette.routing import Mount, Route
from starlette.staticfiles import StaticFiles


# Security model: This server is designed for localhost-only use (binds to 127.0.0.1).
# It has no authentication, no CORS restrictions, and serves all session data to any
# connecting client. Do not expose to a network without adding auth and access controls.


class SecurityHeadersMiddleware(BaseHTTPMiddleware):
    async def dispatch(self, request, call_next):
        response = await call_next(request)
        # NOTE: 'unsafe-inline' for style-src is required because lit-html applies
        # inline styles for dynamic transforms (goose animation positions) and
        # layout. Removing it would require refactoring all inline styles to CSS
        # classes or JS-managed stylesheets.
        response.headers["Content-Security-Policy"] = (
            "default-src 'self'; "
            "script-src 'self' https://cdn.jsdelivr.net; "
            "style-src 'self' 'unsafe-inline' https://fonts.googleapis.com; "
            "font-src https://fonts.gstatic.com; "
            "connect-src 'self'; "
            "img-src 'self' data:; "
            "object-src 'none'; "
            "base-uri 'none'; "
            "frame-ancestors 'none'; "
        )
        response.headers["X-Content-Type-Options"] = "nosniff"
        return response

SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_DIR = os.path.dirname(SCRIPT_DIR)

# â”€â”€ Constants â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
DB_PATH = os.path.expanduser("~/.local/share/goose/sessions/sessions.db")
WALLS_DIR = os.path.expanduser("~/.goosetown/walls")
CHILD_PATTERN = re.compile(r"Task (\d{8}_\d+) started in background")
GTWALL_ID_PATTERN = re.compile(r"Your gtwall ID is (\S+)")
DELEGATE_NAME_PATTERN = re.compile(r"You are (\S+)")
# IMPORTANT: These patterns are duplicated in ui/js/buildings.js (inferRole function).
# If you change patterns here, update the JS version to match.
ROLE_PATTERNS = {
    "orchestrator": re.compile(r"orchestrat", re.I),
    "researcher": re.compile(r"research", re.I),
    "worker": re.compile(r"worker|build|implement", re.I),
    "reviewer": re.compile(r"review|crossfire", re.I),
    "writer": re.compile(r"writ|spec|document", re.I),
}
RING_BUFFER_SIZE = 10000
WALL_LINE_MAX = 10000
ACP_PROTOCOL_VERSION = "v1"

# â”€â”€ State â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
event_buffer: deque = deque(maxlen=RING_BUFFER_SIZE)
event_counter: int = 0
clients: list[asyncio.Queue] = []
latest_wall_lines: deque[dict] = deque(maxlen=WALL_LINE_MAX)
latest_sessions: list[dict] = []
latest_tree: dict = {}
latest_stats: dict = {}
config: dict = {}
wall_generation: int = 0  # bumped on launch to invalidate in-flight wall reads


# â”€â”€ DB â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@contextmanager
def db():
    conn = sqlite3.connect(f"file:{DB_PATH}?mode=ro", uri=True, check_same_thread=False)
    conn.row_factory = sqlite3.Row
    conn.execute("PRAGMA query_only=ON")
    try:
        yield conn.cursor()
    finally:
        conn.close()


def normalize_epoch(ts) -> float:
    if ts is None:
        return 0.0
    ts = float(ts)
    return ts / 1000.0 if ts > 1e12 else ts


# â”€â”€ Session Discovery â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def find_parent_session(cur) -> str | None:
    cur.execute("""
        SELECT DISTINCT s.id FROM sessions s
        JOIN messages m ON m.session_id = s.id
        WHERE s.session_type = 'user'
          AND m.role = 'user'
          AND m.content_json LIKE '%started in background%'
          AND s.updated_at > datetime('now', '-24 hours')
        ORDER BY s.updated_at DESC LIMIT 1
    """)
    if row := cur.fetchone():
        return row[0]
    cur.execute("SELECT id FROM sessions WHERE session_type = 'user' ORDER BY updated_at DESC LIMIT 1")
    return row[0] if (row := cur.fetchone()) else None


def find_wall_file(session_key: str | None = None) -> str | None:
    # Check GOOSE_GTWALL_FILE env var first
    gtwall_file = os.environ.get("GOOSE_GTWALL_FILE", "")
    if gtwall_file and os.path.isfile(gtwall_file):
        return gtwall_file
    
    # Fallback: use session_key if provided
    if session_key:
        path = os.path.join(WALLS_DIR, f"wall-{session_key}.log")
        if os.path.isfile(path):
            return path
    
    # Last resort: newest wall file
    wall_files = glob.glob(os.path.join(WALLS_DIR, "wall-*.log"))
    return max(wall_files, key=os.path.getmtime) if wall_files else None


# â”€â”€ Wall Parsing â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def parse_wall_line(line: str) -> dict:
    parts = line.split("|", 2)
    if len(parts) < 3:
        return {"time": "", "sender_id": "", "message": line, "raw": line, "parse_error": True}
    return {
        "time": parts[0].strip(),
        "sender_id": parts[1].strip(),
        "message": parts[2].strip().replace("\\|", "|"),
        "raw": line,
    }


def wall_line_epoch(parsed: dict) -> float:
    """Parse HH:MM:SS time string to today's epoch. Returns 0 on failure."""
    t = parsed.get("time", "")
    if not t:
        return 0.0
    try:
        today = datetime.now().replace(hour=0, minute=0, second=0, microsecond=0)
        parts = t.split(":")
        return (today.replace(
            hour=int(parts[0]), minute=int(parts[1]),
            second=int(parts[2]) if len(parts) > 2 else 0
        )).timestamp()
    except (ValueError, IndexError):
        return 0.0


# â”€â”€ Tree Building â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def find_children(cur, parent_id: str, _seen: set | None = None) -> list[str]:
    seen = _seen if _seen is not None else set()
    children = []

    # Find delegates spawned by this session (goose run style: "Task X started in background")
    cur.execute(
        "SELECT content_json FROM messages WHERE session_id = ? "
        "AND role = 'user' AND content_json LIKE '%started in background%'",
        (parent_id,),
    )
    for (content_json,) in cur:
        for m in CHILD_PATTERN.finditer(content_json):
            cid = m.group(1)
            if cid not in seen:
                seen.add(cid)
                children.append(cid)

    # ACP-launched sessions: find sub_agent sessions created after the parent.
    # Only applies to sessions launched via ACP (no "started in background" pattern).
    if parent_id in launched_session_ids:
        cur.execute(
            "SELECT id FROM sessions WHERE session_type = 'sub_agent' "
            "AND created_at >= (SELECT created_at FROM sessions WHERE id = ?) "
            "ORDER BY created_at ASC",
            (parent_id,),
        )
        for (cid,) in cur:
            if cid not in seen:
                seen.add(cid)
                children.append(cid)

    # Also find delegates of any UI-launched sessions (tracked in launched_session_ids)
    if _seen is None:
        for sid in launched_session_ids:
            if sid not in seen:
                seen.add(sid)
                children.append(sid)
                children.extend(find_children(cur, sid, seen))

    return children


def extract_gtwall_id(content_json: str) -> str | None:
    if m := GTWALL_ID_PATTERN.search(content_json):
        return m.group(1).strip("`.")
    if m := DELEGATE_NAME_PATTERN.search(content_json):
        return m.group(1).strip("`.")
    return None


def build_sender_session_map(cur, parent_id: str) -> dict[str, str]:
    cur.execute(
        "SELECT role, content_json FROM messages WHERE session_id = ? "
        "AND role IN ('assistant', 'user') ORDER BY created_timestamp ASC",
        (parent_id,),
    )
    tool_id_to_gtwall, tool_id_to_session = {}, {}
    for role, cj_str in cur:
        try:
            items = json.loads(cj_str)
        except (json.JSONDecodeError, TypeError):
            continue
        for item in items:
            if role == "assistant" and item.get("type") == "toolRequest":
                tc = item.get("toolCall", {}).get("value", {})
                if tc.get("name") == "delegate":
                    gid = extract_gtwall_id(tc.get("arguments", {}).get("instructions", ""))
                    if gid:
                        tool_id_to_gtwall[item["id"]] = gid
            elif role == "user" and item.get("type") == "toolResponse":
                text = ""
                try:
                    text = item["toolResult"]["value"]["content"][0]["text"]
                except (KeyError, IndexError, TypeError):
                    pass
                if child_match := CHILD_PATTERN.search(text):
                    tool_id_to_session[item["id"]] = child_match.group(1)
    return {gid: tool_id_to_session[tid] for tid, gid in tool_id_to_gtwall.items() if tid in tool_id_to_session}


def infer_role(session_id: str, name: str, parent_id: str) -> str:
    if session_id == parent_id:
        return "orchestrator"
    for role, pat in ROLE_PATTERNS.items():
        if pat.search(name or ""):
            return role
    return "generic"


def batch_check_errors(cur, session_ids: list[str]) -> set[str]:
    if not session_ids:
        return set()
    placeholders = ",".join("?" * len(session_ids))
    cur.execute(f"""
        SELECT session_id FROM messages
        WHERE session_id IN ({placeholders})
          AND (content_json LIKE '%"isError":true%' OR content_json LIKE '%"isError": true%')
          AND id IN (
            SELECT id FROM messages m2
            WHERE m2.session_id = messages.session_id
            ORDER BY m2.created_timestamp DESC LIMIT 5
          )
    """, session_ids)
    return {row[0] for row in cur.fetchall()}


def infer_status(session: dict, has_error: bool, now: float) -> str:
    if has_error:
        return "error"
    last = normalize_epoch(session.get("last_message_ts", 0))
    if not last and session.get("updated_at"):
        try:
            last = datetime.fromisoformat(session["updated_at"].replace(" ", "T")).timestamp()
        except (ValueError, AttributeError):
            pass
    elapsed = now - last if last else 999
    if elapsed < 15:
        return "active"
    if elapsed < 30:
        return "waiting"
    if elapsed > 120:
        return "complete"
    return "idle"


# â”€â”€ Event Bus â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def publish_event(name: str, data: dict):
    global event_counter
    event_counter += 1
    entry = {"id": event_counter, "event": name, "data": data}
    event_buffer.append(entry)
    for q in clients:
        try:
            q.put_nowait(entry)
        except asyncio.QueueFull:
            pass


def format_sse(eid: int, event: str, data) -> str:
    return f"id: {eid}\nevent: {event}\ndata: {json.dumps(data, default=str)}\n\n"


# â”€â”€ ACP Client â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class AcpClient:
    """Async client for goose ACP (Agent Client Protocol) over stdio JSON-RPC 2.0."""

    def __init__(self, goose_bin: str, env: dict, cwd: str):
        self.goose_bin = goose_bin
        self.env = env
        self.cwd = cwd
        self.process: asyncio.subprocess.Process | None = None
        self.session_id: str | None = None
        self._request_id = 0
        self._read_lock = asyncio.Lock()
        self._write_lock = asyncio.Lock()

    async def start(self):
        """Spawn goose acp and initialize the connection."""
        # Log ACP stderr to a file for debugging
        log_path = os.path.join(WALLS_DIR, f"acp-{os.getpid()}-{int(time.time())}.log")
        os.makedirs(WALLS_DIR, exist_ok=True)
        self._log_fh = open(log_path, "w")
        print(f"ğŸ“ ACP stderr â†’ {log_path}", file=sys.stderr)

        self.process = await asyncio.create_subprocess_exec(
            self.goose_bin, "acp",
            stdin=asyncio.subprocess.PIPE,
            stdout=asyncio.subprocess.PIPE,
            stderr=self._log_fh,
            env=self.env,
            cwd=self.cwd,
        )
        # Initialize handshake
        resp = await self._request("initialize", {
            "protocolVersion": ACP_PROTOCOL_VERSION,
            "clientCapabilities": {},
            "clientInfo": {"name": "goosetown-ui", "version": "1.0.0"},
        })
        if not resp or "result" not in resp:
            raise RuntimeError(f"ACP initialize failed: {resp}")
        caps = resp["result"].get("agentCapabilities", {})
        print(f"ğŸ¤ ACP initialized (loadSession={caps.get('loadSession', False)})", file=sys.stderr)

        # Create a new session
        sess_resp = await self._request("session/new", {
            "mcpServers": [],
            "cwd": self.cwd,
        })
        if not sess_resp or "result" not in sess_resp:
            raise RuntimeError(f"ACP session/new failed: {sess_resp}")
        self.session_id = sess_resp["result"]["sessionId"]
        print(f"ğŸ“‹ ACP session created: {self.session_id}", file=sys.stderr)

    async def prompt(self, text: str):
        """Send a prompt and stream back notifications. Returns the final response."""
        if not self.session_id:
            raise RuntimeError("ACP not initialized â€” call start() first")

        self._request_id += 1
        req_id = self._request_id
        request = {
            "jsonrpc": "2.0",
            "method": "session/prompt",
            "id": req_id,
            "params": {
                "sessionId": self.session_id,
                "prompt": [{"type": "text", "text": text}],
            },
        }

        async with self._write_lock:
            self.process.stdin.write((json.dumps(request) + "\n").encode())
            await self.process.stdin.drain()

        # Read lines until we get our response (id match)
        async with self._read_lock:
            while True:
                line = await self.process.stdout.readline()
                if not line:
                    return None
                try:
                    msg = json.loads(line)
                except json.JSONDecodeError:
                    continue

                # Notification (no id) â€” publish to SSE
                if "method" in msg and "id" not in msg:
                    publish_event("acp_notification", msg.get("params", {}))
                    continue

                # Response matching our request
                if msg.get("id") == req_id:
                    return msg

    async def _request(self, method: str, params: dict | None = None) -> dict | None:
        """Send a simple request (non-streaming, no notification handling)."""
        self._request_id += 1
        req_id = self._request_id
        request = {"jsonrpc": "2.0", "method": method, "id": req_id}
        if params:
            request["params"] = params

        async with self._write_lock:
            self.process.stdin.write((json.dumps(request) + "\n").encode())
            await self.process.stdin.drain()

        async with self._read_lock:
            while True:
                line = await self.process.stdout.readline()
                if not line:
                    return None
                try:
                    msg = json.loads(line)
                except json.JSONDecodeError:
                    continue
                if msg.get("id") == req_id:
                    return msg

    async def stop(self):
        if self.process and self.process.returncode is None:
            self.process.terminate()
            try:
                await asyncio.wait_for(self.process.wait(), timeout=5.0)
            except asyncio.TimeoutError:
                self.process.kill()
        if hasattr(self, "_log_fh"):
            self._log_fh.close()

    @property
    def alive(self) -> bool:
        return self.process is not None and self.process.returncode is None


# â”€â”€ Background Tasks â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
async def wall_watcher():
    wall_path = config.get("wall_file")
    offset = 0
    line_number = 0
    partial = ""

    while True:
        await asyncio.sleep(0.5)

        # Check if config changed (e.g. launch created a new wall file)
        current = config.get("wall_file")
        if current != wall_path:
            print(f"ğŸ“œ wall_watcher: tracking new file {current} (was {wall_path})", file=sys.stderr)
            wall_path = current
            offset = line_number = 0
            partial = ""

        if not wall_path:
            continue  # wait for launch to set a wall file

        try:
            st = os.stat(wall_path)
        except OSError:
            continue

        # File truncated â€” reset
        if st.st_size < offset:
            offset = line_number = 0
            partial = ""
            latest_wall_lines.clear()

        if st.st_size == offset:
            continue

        print(f"ğŸ“œ wall_watcher: file changed, size={st.st_size} offset={offset} gen={wall_generation}", file=sys.stderr)

        # Snapshot generation before reading â€” if it changes mid-read,
        # a launch happened and these lines are stale
        gen = wall_generation

        try:
            with open(wall_path, "r", encoding="utf-8", errors="replace") as f:
                f.seek(offset)
                chunk = f.read()
                offset = f.tell()
        except OSError:
            continue

        chunk = partial + chunk
        lines = chunk.split("\n")
        partial = lines.pop()

        for raw in lines:
            if wall_generation != gen:
                print(f"ğŸ“œ wall_watcher: discarding stale line (gen {gen} != {wall_generation})", file=sys.stderr)
                break
            raw = raw.strip()
            if not raw:
                continue
            line_number += 1
            parsed = parse_wall_line(raw)
            parsed["line"] = line_number
            parsed["_epoch"] = wall_line_epoch(parsed)
            latest_wall_lines.append(parsed)
            publish_event("wall", parsed)
            print(f"ğŸ“œ wall_watcher: published line {line_number}: {raw[:80]}", file=sys.stderr)


async def sessions_tree_watcher():
    global latest_sessions, latest_tree, latest_stats
    parent_id = config.get("parent_session_id")
    prev_sessions_hash = ""
    prev_tree_hash = ""
    prev_stats_hash = ""

    redetect_counter = 0

    while True:
        await asyncio.sleep(1.0)
        try:
            with db() as cur:
                # Only auto-detect parent if we don't have one yet
                # Re-sync parent_id from config (launch may have set it)
                if config.get("parent_session_id") != parent_id:
                    parent_id = config.get("parent_session_id")
                    prev_tree_hash = ""
                    prev_stats_hash = ""

                if not parent_id:
                    # Only auto-detect from launched sessions, not the entire DB
                    if launched_session_ids:
                        parent_id = launched_session_ids[0]
                        config["parent_session_id"] = parent_id
                        prev_tree_hash = ""
                        prev_stats_hash = ""
                        print(f"ğŸ“‹ Detected parent session: {parent_id}", file=sys.stderr)
                if not parent_id:
                    continue
                # Sessions
                cur.execute("""
                    SELECT id, name, session_type AS type, created_at, updated_at,
                        total_tokens, accumulated_total_tokens,
                        accumulated_input_tokens, accumulated_output_tokens,
                        provider_name,
                        json_extract(model_config_json, '$.model_name') AS model
                    FROM sessions
                    WHERE updated_at > datetime('now', '-24 hours')
                    ORDER BY updated_at DESC LIMIT 500
                """)
                rows = [dict(r) for r in cur.fetchall()]
                h = json.dumps([(r["id"], r.get("accumulated_total_tokens"), r.get("updated_at")) for r in rows])
                if h != prev_sessions_hash:
                    prev_sessions_hash = h
                    latest_sessions = rows
                    publish_event("sessions", {"rows": rows})

                # Tree
                child_ids = find_children(cur, parent_id)
                # Merge in sessions launched via /api/launch
                seen = set(child_ids)
                for sid in launched_session_ids:
                    if sid not in seen:
                        child_ids.append(sid)
                        seen.add(sid)
                sender_map = build_sender_session_map(cur, parent_id)
                # Merge launched gtwall names into the sender map
                for sid, gname in launched_gtwall_map.items():
                    if gname not in sender_map:
                        sender_map[gname] = sid
                session_to_gtwall = {sid: gid for gid, sid in sender_map.items()}
                now = time.time()
                children = []

                if child_ids:
                    ph = ",".join("?" * len(child_ids))
                    cur.execute(f"""
                        SELECT s.id, s.name, s.session_type, s.created_at, s.updated_at,
                            s.accumulated_total_tokens,
                            (SELECT COUNT(*) FROM messages m WHERE m.session_id = s.id) AS message_count,
                            (SELECT MAX(m.created_timestamp) FROM messages m WHERE m.session_id = s.id) AS last_message_ts
                        FROM sessions s WHERE s.id IN ({ph})
                        ORDER BY s.created_at ASC
                    """, child_ids)
                    child_rows = [dict(r) for r in cur.fetchall()]

                    error_ids = batch_check_errors(cur, child_ids)

                    for d in child_rows:
                        d["role"] = infer_role(d["id"], d.get("name", ""), parent_id)
                        d["gtwall_id"] = session_to_gtwall.get(d["id"]) or extract_gtwall_id(d.get("name", "")) or ""
                        d["status"] = infer_status(d, d["id"] in error_ids, now)
                        d["tokens"] = d.get("accumulated_total_tokens", 0) or 0
                        created = 0.0
                        if d.get("created_at"):
                            try:
                                created = datetime.fromisoformat(d["created_at"].replace(" ", "T")).timestamp()
                            except (ValueError, AttributeError):
                                pass
                        d["elapsed_seconds"] = round(now - created) if created else 0
                        children.append(d)

                tree = {"parent_session_id": parent_id, "children": children, "sender_map": sender_map}
                th = json.dumps([(c["id"], c.get("status"), c.get("tokens"), c.get("message_count")) for c in children])
                if th != prev_tree_hash:
                    prev_tree_hash = th
                    latest_tree = tree
                    publish_event("tree", tree)

                active = sum(1 for c in children if c.get("status") == "active")
                complete = sum(1 for c in children if c.get("status") == "complete")
                error = sum(1 for c in children if c.get("status") == "error")
                total_tokens = sum(c.get("tokens", 0) for c in children)

                cutoff_ts = now - 60
                rate = sum(1 for ln in latest_wall_lines if ln.get("_epoch", 0) > cutoff_ts)

                stats = {
                    "wall": {"lines_total": len(latest_wall_lines), "rate_per_min": rate},
                    "sessions": {"active": active, "complete": complete, "error": error},
                    "tokens": {"accumulated_total": total_tokens},
                }
                sh = json.dumps(stats, sort_keys=True)
                if sh != prev_stats_hash:
                    prev_stats_hash = sh
                    latest_stats = stats
                    publish_event("stats", stats)

        except Exception as e:
            print(f"âš ï¸  sessions_tree_watcher error: {e}", file=sys.stderr)


async def positions_watcher():
    """Watch .positions/ dir for mtime changes â†’ emit wall_read events."""
    known_mtimes: dict[str, float] = {}
    while True:
        await asyncio.sleep(0.5)
        wall_path = config.get("wall_file")
        if not wall_path:
            continue
        pos_dir = wall_path.removesuffix(".log") + ".positions"
        if not os.path.isdir(pos_dir):
            continue
        for fname in os.listdir(pos_dir):
            if not fname.endswith(".pos"):
                continue
            fpath = os.path.join(pos_dir, fname)
            try:
                mtime = os.path.getmtime(fpath)
            except OSError:
                continue
            reader_id = fname[:-4]  # strip .pos
            if known_mtimes.get(reader_id) != mtime:
                known_mtimes[reader_id] = mtime
                publish_event("wall_read", {
                    "reader_id": reader_id,
                    "timestamp": time.time(),
                })


# â”€â”€ SSE Endpoint â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
async def sse_endpoint(request):
    if len(clients) > 50:
        return JSONResponse({"error": "too many connections"}, status_code=503)
    queue: asyncio.Queue = asyncio.Queue(maxsize=1000)
    clients.append(queue)
    last_event_id = request.headers.get("Last-Event-ID")

    async def generate():
        try:
            bootstrap_data = json.dumps({
                "wall": {"wall_id": config.get("wall_id", ""), "lines": list(latest_wall_lines)},
                "sessions": {"rows": latest_sessions},
                "tree": latest_tree,
                "stats": latest_stats,
            }, default=str)
            yield f"event: bootstrap\ndata: {bootstrap_data}\n\n"

            if last_event_id:
                try:
                    lid = int(last_event_id)
                    for entry in event_buffer:
                        if entry["id"] > lid:
                            yield format_sse(entry["id"], entry["event"], entry["data"])
                except (ValueError, TypeError):
                    pass

            while True:
                try:
                    entry = await asyncio.wait_for(queue.get(), timeout=15.0)
                    yield format_sse(entry["id"], entry["event"], entry["data"])
                except asyncio.TimeoutError:
                    yield ": heartbeat\n\n"
        finally:
            if queue in clients:
                clients.remove(queue)

    return StreamingResponse(
        generate(),
        media_type="text/event-stream",
        headers={"Cache-Control": "no-cache", "Connection": "keep-alive", "X-Accel-Buffering": "no"},
    )


# â”€â”€ REST â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
async def messages_endpoint(request):
    sid = request.path_params["session_id"]
    if not re.match(r'^[a-zA-Z0-9_-]{1,128}$', sid):
        return JSONResponse({"error": "invalid session id"}, status_code=400)
    before = request.query_params.get("before")

    try:
        limit = max(1, min(int(request.query_params.get("limit", "100")), 500))
        with db() as cur:
            if before:
                cur.execute(
                    "SELECT id, role, content_json, created_timestamp FROM messages "
                    "WHERE session_id = ? AND created_timestamp < ? "
                    "ORDER BY created_timestamp DESC LIMIT ?",
                    (sid, before, limit),
                )
            else:
                cur.execute(
                    "SELECT id, role, content_json, created_timestamp FROM messages "
                    "WHERE session_id = ? ORDER BY created_timestamp DESC LIMIT ?",
                    (sid, limit),
                )
            rows = [{"id": r[0], "role": r[1], "content_json": r[2], "created_timestamp": r[3]} for r in cur.fetchall()]
    except Exception as e:
        print(f"âš ï¸  messages_endpoint error: {e}", file=sys.stderr)
        return JSONResponse({"error": "internal error"}, status_code=500)

    rows.reverse()
    return JSONResponse({"session_id": sid, "messages": rows, "has_more": len(rows) == limit})


async def wall_post_endpoint(request):
    """Post a message to gtwall as 'user'. Shells out to ./gtwall â€” no duplicated logic.

    NOTE: This endpoint has no authentication. It is safe only because the server
    binds to 127.0.0.1 (localhost). Do not expose to a network without adding auth.
    """
    try:
        body = await request.json()
        message = body.get("message", "").strip()
        if not message:
            return JSONResponse({"error": "empty message"}, status_code=400)
        if len(message) > 4096:
            return JSONResponse({"error": "message too long (max 4096 chars)"}, status_code=400)

        wall_file = config.get("wall_file", "")
        if not wall_file:
            return JSONResponse({"error": "no wall file configured"}, status_code=503)

        gtwall_path = os.path.join(PROJECT_DIR, "gtwall")
        env = {**os.environ, "GOOSE_GTWALL_FILE": wall_file}
        proc = await asyncio.create_subprocess_exec(
            gtwall_path, "user", message,
            env=env,
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE,
        )
        await proc.wait()
        if proc.returncode != 0:
            stderr_output = (await proc.stderr.read()).decode().strip()
            print(f"âš ï¸  gtwall failed (rc={proc.returncode}): {stderr_output}", file=sys.stderr)
            return JSONResponse({"error": "failed to post message"}, status_code=500)

        # Auto-prompt the ACP orchestrator to check the wall
        acp: AcpClient | None = launch_state.get("acp")
        if acp and acp.alive:
            nudge = f"A human just posted on the wall: \"{message}\". Read the wall with ./gtwall goose-orchestrator and respond."
            asyncio.create_task(_acp_prompt_task(acp, nudge))

        return JSONResponse({"ok": True})
    except Exception as e:
        print(f"âš ï¸  wall_post error: {e}", file=sys.stderr)
        return JSONResponse({"error": "internal error"}, status_code=500)


# â”€â”€ Launch Control â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
launch_state: dict = {"acp": None, "wall_file": None, "started_at": None}
launched_session_ids: list[str] = []  # sessions launched via /api/launch
launched_gtwall_map: dict[str, str] = {}  # session_id â†’ gtwall display name


async def launch_endpoint(request):
    """Spawn a persistent goose orchestrator via ACP."""
    acp: AcpClient | None = launch_state.get("acp")

    # If an orchestrator is still running, retire it first
    if acp and acp.alive:
        publish_event("launch", {"status": "stopping", "pid": acp.process.pid})
        print(f"ğŸ›‘ Retiring old ACP orchestrator (pid={acp.process.pid})", file=sys.stderr)
        await acp.stop()
        launch_state["acp"] = None

    # Fresh start â€” clear old launch tracking
    launched_session_ids.clear()
    launched_gtwall_map.clear()
    config["parent_session_id"] = None

    try:
        body = await request.json()
    except Exception:
        return JSONResponse({"error": "invalid json"}, status_code=400)

    prompt = body.get("prompt", "").strip()
    if not prompt:
        return JSONResponse({"error": "prompt required"}, status_code=400)

    # Always create a fresh wall file for each launch
    os.makedirs(WALLS_DIR, exist_ok=True)
    wall_id = f"{os.getpid()}-{int(time.time())}"
    wall_file = os.path.join(WALLS_DIR, f"wall-{wall_id}.log")
    Path(wall_file).touch()
    config["wall_file"] = wall_file
    config["wall_id"] = wall_id

    # Reset wall state so the UI starts fresh â€” bump generation to invalidate
    # any in-flight wall_watcher reads from the old file
    global wall_generation
    wall_generation += 1
    latest_wall_lines.clear()
    publish_event("wall_reset", {"wall_id": wall_id, "wall_file": wall_file})

    # Build env â€” inherit current env, set wall file for ./goose wrapper
    env = os.environ.copy()
    env["GOOSE_GTWALL_FILE"] = wall_file

    # Use the real goose binary for ACP (not the ./goose wrapper which adds
    # shell overhead and cleanup traps incompatible with stdio JSON-RPC)
    goose_bin = os.environ.get("GOOSE_BIN") or "goose"

    # Start ACP client
    try:
        acp = AcpClient(goose_bin, env, PROJECT_DIR)
        await acp.start()
    except Exception as e:
        return JSONResponse({"error": f"ACP start failed: {e}"}, status_code=500)

    launch_state.update(acp=acp, wall_file=wall_file, started_at=time.time())

    # Track the ACP session so the tree watcher picks it up
    launched_session_ids.append(acp.session_id)
    launched_gtwall_map[acp.session_id] = "goose-orchestrator"
    config["parent_session_id"] = acp.session_id

    publish_event("launch", {"status": "started", "pid": acp.process.pid, "wall_file": wall_file, "session_id": acp.session_id})
    print(f"ğŸš€ ACP orchestrator started (pid={acp.process.pid}, session={acp.session_id}), wall={wall_file}", file=sys.stderr)

    # Prepend identity context so the orchestrator knows its wall name
    full_prompt = (
        "You are goose-orchestrator. Your gtwall ID is goose-orchestrator. "
        "Always use goose-orchestrator as your sender ID when posting to the wall.\n\n"
        + prompt
    )

    # Send initial prompt in the background so we don't block the HTTP response
    asyncio.create_task(_acp_prompt_task(acp, full_prompt))

    return JSONResponse({"ok": True, "pid": acp.process.pid, "wall_file": wall_file, "wall_id": wall_id, "session_id": acp.session_id})


async def _acp_prompt_task(acp: AcpClient, text: str):
    """Run a prompt in the background, publishing notifications to SSE."""
    try:
        resp = await acp.prompt(text)
        if resp and "error" in resp:
            publish_event("acp_error", resp["error"])
            print(f"âš ï¸  ACP prompt error: {resp['error']}", file=sys.stderr)
        else:
            publish_event("acp_complete", {"session_id": acp.session_id})
    except Exception as e:
        publish_event("acp_error", {"message": str(e)})
        print(f"âš ï¸  ACP prompt exception: {e}", file=sys.stderr)


async def prompt_endpoint(request):
    """Send a follow-up message to the running ACP orchestrator."""
    acp: AcpClient | None = launch_state.get("acp")
    if not acp or not acp.alive:
        return JSONResponse({"error": "no running orchestrator"}, status_code=404)

    try:
        body = await request.json()
    except Exception:
        return JSONResponse({"error": "invalid json"}, status_code=400)

    message = body.get("message", "").strip()
    if not message:
        return JSONResponse({"error": "message required"}, status_code=400)

    asyncio.create_task(_acp_prompt_task(acp, message))
    return JSONResponse({"ok": True, "session_id": acp.session_id})


async def launch_status_endpoint(request):
    """Return current launch state."""
    acp: AcpClient | None = launch_state.get("acp")
    if not acp:
        return JSONResponse({"status": "idle"})

    if acp.alive:
        elapsed = round(time.time() - launch_state["started_at"]) if launch_state["started_at"] else 0
        return JSONResponse({
            "status": "running",
            "pid": acp.process.pid,
            "session_id": acp.session_id,
            "wall_file": launch_state["wall_file"],
            "elapsed_seconds": elapsed,
        })
    else:
        return JSONResponse({
            "status": "exited",
            "pid": acp.process.pid,
            "session_id": acp.session_id,
            "exit_code": acp.process.returncode,
            "wall_file": launch_state["wall_file"],
        })


async def launch_stop_endpoint(request):
    """Stop the running ACP orchestrator."""
    acp: AcpClient | None = launch_state.get("acp")
    if not acp or not acp.alive:
        return JSONResponse({"error": "no running orchestration"}, status_code=404)

    pid = acp.process.pid
    await acp.stop()
    publish_event("launch", {"status": "stopping", "pid": pid})
    print(f"ğŸ›‘ Stopping ACP orchestrator (pid={pid})", file=sys.stderr)
    return JSONResponse({"ok": True, "pid": pid})
async def config_endpoint(request):
    safe_keys = ("wall_id", "port", "parent_session_id")
    return JSONResponse({k: config[k] for k in safe_keys if k in config})


async def root_redirect(request):
    return RedirectResponse(url="/ui/index.html")


# â”€â”€ App â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def create_app() -> Starlette:
    ui_dir = os.path.join(PROJECT_DIR, "ui")
    town_dir = os.path.join(PROJECT_DIR, "ui", "town")
    os.makedirs(town_dir, exist_ok=True)
    return Starlette(
        routes=[
            Route("/", root_redirect),
            Route("/events", sse_endpoint),
            Route("/api/messages/{session_id}", messages_endpoint),
            Route("/api/wall", wall_post_endpoint, methods=["POST"]),
            Route("/api/launch", launch_endpoint, methods=["POST"]),
            Route("/api/launch/status", launch_status_endpoint),
            Route("/api/launch/stop", launch_stop_endpoint, methods=["POST"]),
            Route("/api/prompt", prompt_endpoint, methods=["POST"]),
            Route("/api/config", config_endpoint),
            Mount("/ui/town", StaticFiles(directory=town_dir, html=True), name="town"),
            Mount("/ui", StaticFiles(directory=ui_dir), name="ui"),
        ],
        middleware=[Middleware(SecurityHeadersMiddleware)],
        on_startup=[start_background_tasks],
    )


async def start_background_tasks():
    asyncio.create_task(wall_watcher())
    asyncio.create_task(sessions_tree_watcher())
    asyncio.create_task(positions_watcher())


# â”€â”€ CLI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def main():
    parser = argparse.ArgumentParser(description="goosetown-ui dashboard server")
    parser.add_argument("--session", help="Parent session ID (auto-detect if omitted)")
    parser.add_argument("--port", type=int, default=4242, help="Port (default: 4242)")
    parser.add_argument("--wall", help="Wall file path (auto-detect if omitted)")
    args = parser.parse_args()

    # Only use explicit --session/--wall args; otherwise start clean and wait for launch
    parent_id = args.session or None
    wall_file = args.wall or None
    wall_id = ""

    if parent_id:
        print(f"ğŸ“‹ Parent session: {parent_id}", file=sys.stderr)
    if wall_file:
        wall_id = Path(wall_file).stem.removeprefix("wall-")
        print(f"ğŸ“œ Wall file: {wall_file}", file=sys.stderr)

    if not parent_id and not wall_file:
        print("ğŸ§¹ Starting clean â€” use Launch Orchestrator to begin", file=sys.stderr)

    config.update({
        "parent_session_id": parent_id,
        "wall_file": wall_file,
        "wall_id": wall_id,
        "db_path": DB_PATH,
        "port": args.port,
    })

    print(f"\nğŸ­ gooseTown dashboard: http://localhost:{args.port}/\n", file=sys.stderr)
    uvicorn.run(create_app(), host="127.0.0.1", port=args.port, log_level="warning")


if __name__ == "__main__":
    main()
